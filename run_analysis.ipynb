{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from utils import tensor_to_image, get_ssim_all\n",
    "from reconstruction import compute_recovery_order_MSE\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNS_DIR = \"outputs/\"\n",
    "INFO_EXTENSION = \"_info.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"./figures\"):\n",
    "    os.makedirs(\"./figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\"font.size\": 20, \"legend.fontsize\": 14})\n",
    "markers = [\"o\", \"s\", \"^\", \"P\"]\n",
    "cud_colors = [\"#377eb8\", \"#ff7f00\", \"#4daf4a\", \"#984ea3\"]  # Blue, Orange, Green, Dark Purple\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(color=cud_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, filters_dict):\n",
    "    for k, v in filters_dict.items():\n",
    "        if isinstance(v, int) or isinstance(v, float) or isinstance(v, str):\n",
    "            df = df[df[k] == v]\n",
    "        elif isinstance(v, list):\n",
    "            df = df[df[k].isin(v)]\n",
    "        else:\n",
    "            raise ValueError(\"Filter values must be int, str or list\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for filename in os.listdir(RUNS_DIR):\n",
    "    if filename.endswith(INFO_EXTENSION):\n",
    "        with open(os.path.join(RUNS_DIR, filename), \"r\") as f:\n",
    "            run_data = json.load(f)\n",
    "            data.append(run_data)\n",
    "\n",
    "df_full = pd.json_normalize(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recovery_statistics(original_data, recovered_images):\n",
    "    min_n = min(original_data.shape[0], recovered_images.shape[0])\n",
    "    dssims_all = (1 - get_ssim_all(recovered_images, original_data)) / 2\n",
    "    dssims_best, nns_dssim = dssims_all.min(dim=0)\n",
    "    mse_best, nns_mse, recovery_order_mse = compute_recovery_order_MSE(recovered_images, original_data)\n",
    "\n",
    "    qs = torch.tensor([0.25, 0.5, 0.75]).to(device=mse_best.device, dtype=mse_best.dtype)\n",
    "    mse_quantiles = torch.quantile(mse_best[:min_n], qs)\n",
    "    dssim_quantiles = torch.quantile(dssims_best[:min_n], qs)\n",
    "\n",
    "    dssims_best_reversed, nns_dssim_reversed = dssims_all.min(dim=1)\n",
    "    unique_reconstructions = []\n",
    "    for i, j in enumerate(nns_dssim):\n",
    "        if nns_dssim_reversed[j] == i:\n",
    "            unique_reconstructions.append(i)\n",
    "    unique_recoveries = len(unique_reconstructions)\n",
    "    good_unique_recoveries = torch.count_nonzero(dssims_best[unique_reconstructions] <= 0.3).item()\n",
    "\n",
    "    return {\n",
    "        \"unique_recoveries_percent\": unique_recoveries / min_n * 100,\n",
    "        \"good_uniques_percent\": good_unique_recoveries / min_n * 100,\n",
    "        \"dssim_q0\": round(dssim_quantiles[0].item(), 3),\n",
    "        \"dssim_q1\": round(dssim_quantiles[1].item(), 3),\n",
    "        \"dssim_q2\": round(dssim_quantiles[2].item(), 3),\n",
    "        \"mse_q0\": round(mse_quantiles[0].item(), 3),\n",
    "        \"mse_q1\": round(mse_quantiles[1].item(), 3),\n",
    "        \"mse_q2\": round(mse_quantiles[2].item(), 3),\n",
    "    }, dssims_best.numpy(), nns_dssim.numpy(), mse_best.numpy(), nns_mse.numpy(), unique_reconstructions\n",
    "\n",
    "\n",
    "def get_run_statistics_from_name(run_name, return_full=False):\n",
    "    saved_data = np.load(os.path.join(RUNS_DIR, run_name + \"_results.npz\"))\n",
    "    original_data, recovered_images = torch.tensor(saved_data['trainig_data']), torch.tensor(saved_data['reconstructions'])\n",
    "    if return_full:\n",
    "        return *get_recovery_statistics(original_data, recovered_images), tensor_to_image(original_data), tensor_to_image(recovered_images)\n",
    "    return get_recovery_statistics(original_data, recovered_images)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstructions Quality Laplace and RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_lap = {\"recovery_size\": 500, \"target_model\": \"laplace\", \"dataset\": \"CIFAR5M\", \"horiz_flip\": False, \"recovery_gamma\": 0.15, \n",
    "                    \"target_gamma\": 0.15, \"recovery_pca_dim\": 0, \"use_test_time_seed\": True, \"target_regularization\": 0}\n",
    "filters_rbf = {\"recovery_size\": 500, \"target_model\": \"gaussian\", \"dataset\": \"CIFAR5M\", \"horiz_flip\": False, \"recovery_gamma\": 0.003, \"recovery_pca_dim\": 0, \n",
    "                    \"use_test_time_seed\": True, \"target_regularization\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "marker_count = 0\n",
    "\n",
    "for model_name, filters in [(\"Laplace\", filters_lap), (\"RBF\", filters_rbf)]:\n",
    "    df = filter_df(df_full, filters)\n",
    "    df = df[df.batch_size < 500000]\n",
    "    df = df.sort_values(\"target_task\")\n",
    "    for i, task in enumerate(df['target_task'].unique()):\n",
    "        cur_df = df[df['target_task'] == task].sort_values(\"batch_size\")\n",
    "        dssim_values = []\n",
    "        x_ticks = []\n",
    "\n",
    "        for _, row in cur_df.iterrows():\n",
    "            stats = get_run_statistics_from_name(row['wandb_run_name'])\n",
    "            dssim_values.append(stats['dssim_q1'])\n",
    "            x_ticks.append(row.batch_size / (10 ** 5))\n",
    "\n",
    "        plt.plot(x_ticks, dssim_values, label=f\"{model_name} {task.upper()}\", marker=markers[marker_count], linewidth=5, markersize=12)\n",
    "        marker_count += 1\n",
    "\n",
    "plt.axvline(x=500 * (3072 + 10) / 10 / 10**5 , color='black', linestyle='--', linewidth=2, label=r\"$m=\\frac{n(d+C)}{C}$\")\n",
    "plt.legend()\n",
    "plt.grid(visible=True, which='major', linestyle='--', linewidth=0.5)\n",
    "plt.xlabel(r\"Query Points ($\\times 10^5$)\")\n",
    "plt.ylabel(\"Median DSSIM\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/dssim_vs_equations.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equations vs Reconstruction Quality PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_dict = {\"recovery_size\": 100, \"dataset\": \"CIFAR10\", \"horiz_flip\": False, \"recovery_gamma\": 0.15, \"recovery_model\": \"laplace\"}\n",
    "df = filter_df(df_full, filters_dict)\n",
    "df = df[(df.batch_size < 500000) & (df.batch_size % 10000 == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = plt.get_cmap(\"tab10\")\n",
    "num_plots = len(df['recovery_pca_dim'].unique())\n",
    "colors = [cmap(i / num_plots) for i in range(num_plots)]\n",
    "df.loc[df['recovery_pca_dim'] == 0, 'recovery_pca_dim'] = 3072\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "marker_count = 0\n",
    "\n",
    "for i, dim in enumerate(np.sort(df['recovery_pca_dim'].unique())):\n",
    "    cur_df = df[df['recovery_pca_dim'] == dim].sort_values(\"batch_size\")\n",
    "        \n",
    "    dssim_values = []\n",
    "    x_ticks = []\n",
    "    params = 100 * (3072 + 10)\n",
    "\n",
    "    for _, row in tqdm(cur_df.iterrows()):\n",
    "        stats = get_run_statistics_from_name(row['wandb_run_name'])\n",
    "        dssim_values.append(stats['dssim_q1'])\n",
    "        x_ticks.append(row.batch_size / 10000)\n",
    "\n",
    "    label = dim if dim != 3072 else \"3072 (No PCA)\" \n",
    "    plt.plot(x_ticks, dssim_values, label=label, color=colors[i], marker=markers[marker_count], linewidth=5, markersize=12)\n",
    "    marker_count += 1\n",
    "\n",
    "plt.axvline(x=100 * (3072 + 10) / 10 / 10**4 , color='black', linestyle='--', linewidth=2, label=r\"$m=\\frac{n(d+C)}{C}$\")\n",
    "plt.legend(title=\"PCA Dimension\")\n",
    "plt.grid(visible=True, which='major', linestyle='--', linewidth=0.5)\n",
    "plt.xlabel(r\"Query Points ($\\times 10^4$)\")\n",
    "plt.ylabel(\"Median DSSIM\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/pca_cifar10_n100.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruction Quality vs Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_laplace = {\"recovery_size\": 500, \"target_model\": \"laplace\", \"dataset\": \"CIFAR5M\", \"horiz_flip\": False,\n",
    "                       \"recovery_pca_dim\": 0, \"use_test_time_seed\": True, \"target_regularization\": 0, \"batch_size\": 500000, \n",
    "                       \"target_task\": \"krr\"}\n",
    "df = filter_df(df_full, filters_laplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "cur_df = df.sort_values(\"recovery_gamma\")\n",
    "dssims = []\n",
    "gammas = []\n",
    "\n",
    "for _, row in cur_df.iterrows():\n",
    "    stats = get_run_statistics_from_name(row['wandb_run_name'])\n",
    "    dssims.append(stats['dssim_q1'])\n",
    "    gammas.append(row.recovery_gamma)\n",
    "\n",
    "plt.plot(gammas, dssims, marker=\"o\", linewidth=5, markersize=12)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(visible=True, which='major', linestyle='--', linewidth=0.5)\n",
    "plt.xlabel(r\"$\\gamma$\")\n",
    "plt.ylabel(\"Median DSSIM\")\n",
    "plt.tight_layout()\n",
    "ticks = cur_df.recovery_gamma.unique()[::2]\n",
    "plt.xticks(ticks)\n",
    "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda val, _: f\"{val:.2f}\"))\n",
    "plt.savefig(\"figures/gamma_laplace.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main CIFAR Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace every WANDB_RUN_NAME with the relevant run name (e.g. \"floral-morning-48\")\n",
    "our_runs_cifar = [\n",
    "        \"WANDB_RUN_NAME\", #Laplace\n",
    "        \"WANDB_RUN_NAME\", #RBF\n",
    "        \"WANDB_RUN_NAME\", #NTK\n",
    "        \"WANDB_RUN_NAME\" #polynomial kernel\n",
    "]\n",
    "\n",
    "our_labels_cifar = [\"Laplace\", \"RBF\", \"NTK\", \"Cubic Polynomial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_stats_cifar = {}\n",
    "our_dssims_cifar = {}\n",
    "our_nns_dssim_cifar = {}\n",
    "our_mses_cifar = {}\n",
    "our_nns_mse_cifar = {}\n",
    "our_recovered_images_cifar = {}\n",
    "ours_mutual_nn_cifar = {}\n",
    "original_data = None\n",
    "\n",
    "for i, k in enumerate(our_runs_cifar):\n",
    "    stats, dssims, nns_dssim, mses, nns_mses, mutual_nns, cur_original_data, recovered_images= get_run_statistics_from_name(k, return_full=True)\n",
    "    if original_data is None:\n",
    "        original_data = cur_original_data\n",
    "    else:\n",
    "        assert np.allclose(original_data, cur_original_data)\n",
    "    our_stats_cifar[our_labels_cifar[i]] = stats\n",
    "    our_dssims_cifar[our_labels_cifar[i]] = dssims\n",
    "    our_nns_dssim_cifar[our_labels_cifar[i]] = nns_dssim\n",
    "    our_recovered_images_cifar[our_labels_cifar[i]] = recovered_images\n",
    "    our_mses_cifar[our_labels_cifar[i]] = mses\n",
    "    our_nns_mse_cifar[our_labels_cifar[i]] = nns_mses\n",
    "    ours_mutual_nn_cifar[our_labels_cifar[i]] = mutual_nns\n",
    "\n",
    "# count per image how often is is in the mutual nn list\n",
    "mutual_nn_counts = np.unique(np.concatenate(list(ours_mutual_nn_cifar.values())), return_counts=True)\n",
    "good_by_mutual_nn = mutual_nn_counts[0][mutual_nn_counts[1] >= 2]\n",
    "# all_dists = np.stack([dssims for dssims in our_dssims_cifar.values()])\n",
    "all_dists = np.stack([mses for mses in our_mses_cifar.values()])\n",
    "nns = our_nns_mse_cifar\n",
    "recovery_order = np.argsort(all_dists.mean(axis=0))\n",
    "\n",
    "fig, axes = plt.subplots(5, 20, figsize=(40, 10))\n",
    "for i, (k, dssims) in enumerate(our_dssims_cifar.items()):\n",
    "    recovered_data = our_recovered_images_cifar[k]\n",
    "\n",
    "    for j in range(20):\n",
    "        axes[i, j].imshow(recovered_data[nns[k][recovery_order[j]]])\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "for j in range(20):\n",
    "    axes[-1, j].imshow(original_data[recovery_order[j]])\n",
    "    axes[-1, j].axis('off')\n",
    "\n",
    "plt.subplots_adjust(wspace=0, hspace=0) \n",
    "fig.text(0.114, 0.8, 'Laplace', ha = 'center', fontsize = 20, rotation = 90, va = 'center')\n",
    "fig.text(0.114, 0.65, 'RBF', ha = 'center', fontsize = 20, rotation = 90, va = 'center')\n",
    "fig.text(0.114, 0.5, 'NTK', ha = 'center', fontsize = 20, rotation = 90, va = 'center')\n",
    "fig.text(0.114, 0.35, 'Cubic', ha = 'center', fontsize = 20, rotation = 90, va = 'center')\n",
    "fig.text(0.114, 0.19, 'Dataset', ha = 'center', fontsize = 20, rotation = 90, va = 'center')\n",
    "fig.savefig(\"figures/cifar top reconstructions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "marker_count = 0\n",
    "\n",
    "for k, dssims in our_dssims_cifar.items():\n",
    "    plt.plot(np.arange(1, 501), np.sort(dssims), label=k, linewidth=5)\n",
    "    marker_count += 1\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(visible=True, which='major', linestyle='--', linewidth=0.5)\n",
    "plt.xlabel(\"Image Index\")\n",
    "plt.ylabel(\"DSSIM\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/recon_quality_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "marker_count = 0\n",
    "\n",
    "max_dssim = np.max([np.max(dssims) for dssims in our_dssims_cifar.values()])\n",
    "\n",
    "for k, dssims in our_dssims_cifar.items():\n",
    "    sorted_dssims = np.concatenate([np.array([0]), np.sort(dssims), np.array([max_dssim])])\n",
    "    proportion = np.arange(sorted_dssims.shape[0]) / sorted_dssims.shape[0]\n",
    "    plt.plot(sorted_dssims, proportion, label=k, linewidth=5)\n",
    "    marker_count += 1\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(visible=True, which='major', linestyle='--', linewidth=0.5)\n",
    "plt.xlabel(\"DSSIM\")\n",
    "plt.ylabel(\"Proportion\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/recon_quality_edcf.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, stats in our_stats_cifar.items():\n",
    "    print(f\"{k}: {stats}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
